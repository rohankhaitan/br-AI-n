{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b29cd2b-8313-41fa-b3c3-e0178ab80abb",
   "metadata": {},
   "source": [
    "#### Comparison of performance of Bayesian Neural Network using Varitional Inference and HMC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a43ad-daa5-4e21-bab9-448ea350387c",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9f9cdc-f676-4877-9c4f-c3ec041107d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using StatsBase\n",
    "using Flux\n",
    "using Distributions, Random\n",
    "using Turing\n",
    "using Metrics\n",
    "using Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14223f56-180c-4cdc-aae8-594e27495c99",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df374142-7ec7-4ecf-924a-479d1c5faa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\khaitan\\\\Downloads\\\\iris_data\\\\iris.csv\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = raw\"C:\\Users\\khaitan\\Downloads\\iris_data\\iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b95a74-793a-4ca4-a02a-22e7d281370d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 5 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>f1</th><th>f2</th><th>f3</th><th>f4</th><th>class</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"String15\">String15</th></tr></thead><tbody><tr><th>1</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>2</th><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>3</th><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>4</th><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>5</th><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& f1 & f2 & f3 & f4 & class\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & String15\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & Iris-setosa \\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & Iris-setosa \\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & Iris-setosa \\\\\n",
       "\t4 & 4.6 & 3.1 & 1.5 & 0.2 & Iris-setosa \\\\\n",
       "\t5 & 5.0 & 3.6 & 1.4 & 0.2 & Iris-setosa \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m f1      \u001b[0m\u001b[1m f2      \u001b[0m\u001b[1m f3      \u001b[0m\u001b[1m f4      \u001b[0m\u001b[1m class       \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String15    \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────\n",
       "   1 │     5.1      3.5      1.4      0.2  Iris-setosa\n",
       "   2 │     4.9      3.0      1.4      0.2  Iris-setosa\n",
       "   3 │     4.7      3.2      1.3      0.2  Iris-setosa\n",
       "   4 │     4.6      3.1      1.5      0.2  Iris-setosa\n",
       "   5 │     5.0      3.6      1.4      0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CSV.File(file_path, header=[\"f1\",\"f2\",\"f3\",\"f4\", \"class\"]) |> DataFrame\n",
    "first(df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de54cc-6a7a-4e96-a370-61daa6ae2534",
   "metadata": {},
   "source": [
    "### Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a8bf4c-9414-44c6-bf7e-6bd7d577238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 5 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>f1</th><th>f2</th><th>f3</th><th>f4</th><th>class</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"String15\">String15</th></tr></thead><tbody><tr><th>1</th><td>5.1</td><td>3.3</td><td>1.7</td><td>0.5</td><td>Iris-setosa</td></tr><tr><th>2</th><td>4.7</td><td>3.2</td><td>1.6</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>3</th><td>6.9</td><td>3.1</td><td>5.4</td><td>2.1</td><td>Iris-virginica</td></tr><tr><th>4</th><td>6.3</td><td>3.4</td><td>5.6</td><td>2.4</td><td>Iris-virginica</td></tr><tr><th>5</th><td>7.7</td><td>3.0</td><td>6.1</td><td>2.3</td><td>Iris-virginica</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& f1 & f2 & f3 & f4 & class\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & String15\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.3 & 1.7 & 0.5 & Iris-setosa \\\\\n",
       "\t2 & 4.7 & 3.2 & 1.6 & 0.2 & Iris-setosa \\\\\n",
       "\t3 & 6.9 & 3.1 & 5.4 & 2.1 & Iris-virginica \\\\\n",
       "\t4 & 6.3 & 3.4 & 5.6 & 2.4 & Iris-virginica \\\\\n",
       "\t5 & 7.7 & 3.0 & 6.1 & 2.3 & Iris-virginica \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m f1      \u001b[0m\u001b[1m f2      \u001b[0m\u001b[1m f3      \u001b[0m\u001b[1m f4      \u001b[0m\u001b[1m class          \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String15       \u001b[0m\n",
       "─────┼────────────────────────────────────────────────────\n",
       "   1 │     5.1      3.3      1.7      0.5  Iris-setosa\n",
       "   2 │     4.7      3.2      1.6      0.2  Iris-setosa\n",
       "   3 │     6.9      3.1      5.4      2.1  Iris-virginica\n",
       "   4 │     6.3      3.4      5.6      2.4  Iris-virginica\n",
       "   5 │     7.7      3.0      6.1      2.3  Iris-virginica"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[shuffle(1:end), :]\n",
    "first(df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1cd78-e695-4a68-b4b9-dd2ce3d0e1fe",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117acc68-57c8-4ff0-b813-19f977e1b673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 3 entries:\n",
       "  \"Iris-virginica\"  => 2\n",
       "  \"Iris-setosa\"     => 0\n",
       "  \"Iris-versicolor\" => 1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux = unique(df.class)\n",
    "D = Dict(\"Iris-setosa\" => 0, \"Iris-versicolor\" => 1, \"Iris-virginica\" => 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d204b5a7-b386-4d69-80ef-bef159461a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(x) = floor(Int, x)\n",
    "df.label = [0 for i in 1:size(df, 1)]\n",
    "for i in 1:length(df.class)\n",
    "    df.label[i] = D[df.class[i]]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7392df-5406-487a-aaf1-2247da0e9f5b",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e207ad-51ac-480e-9b9c-143edcab1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.encoded_label = [[0, 0, 0] for i in 1:size(df, 1)]\n",
    "for i in 1:length(df.label)\n",
    "    df.encoded_label[i][int(df.label[i]) + 1] = 1\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b052f802-7b2f-4fcf-b091-501a1f5f88dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>f1</th><th>f2</th><th>f3</th><th>f4</th><th>class</th><th>label</th><th>encoded_label</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"String15\">String15</th><th title=\"Int64\">Int64</th><th title=\"Vector{Int64}\">Array…</th></tr></thead><tbody><tr><th>1</th><td>5.1</td><td>3.3</td><td>1.7</td><td>0.5</td><td>Iris-setosa</td><td>0</td><td>[1, 0, 0]</td></tr><tr><th>2</th><td>4.7</td><td>3.2</td><td>1.6</td><td>0.2</td><td>Iris-setosa</td><td>0</td><td>[1, 0, 0]</td></tr><tr><th>3</th><td>6.9</td><td>3.1</td><td>5.4</td><td>2.1</td><td>Iris-virginica</td><td>2</td><td>[0, 0, 1]</td></tr><tr><th>4</th><td>6.3</td><td>3.4</td><td>5.6</td><td>2.4</td><td>Iris-virginica</td><td>2</td><td>[0, 0, 1]</td></tr><tr><th>5</th><td>7.7</td><td>3.0</td><td>6.1</td><td>2.3</td><td>Iris-virginica</td><td>2</td><td>[0, 0, 1]</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& f1 & f2 & f3 & f4 & class & label & encoded\\_label\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & String15 & Int64 & Array…\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.3 & 1.7 & 0.5 & Iris-setosa & 0 & [1, 0, 0] \\\\\n",
       "\t2 & 4.7 & 3.2 & 1.6 & 0.2 & Iris-setosa & 0 & [1, 0, 0] \\\\\n",
       "\t3 & 6.9 & 3.1 & 5.4 & 2.1 & Iris-virginica & 2 & [0, 0, 1] \\\\\n",
       "\t4 & 6.3 & 3.4 & 5.6 & 2.4 & Iris-virginica & 2 & [0, 0, 1] \\\\\n",
       "\t5 & 7.7 & 3.0 & 6.1 & 2.3 & Iris-virginica & 2 & [0, 0, 1] \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m f1      \u001b[0m\u001b[1m f2      \u001b[0m\u001b[1m f3      \u001b[0m\u001b[1m f4      \u001b[0m\u001b[1m class          \u001b[0m\u001b[1m label \u001b[0m\u001b[1m encoded_labe\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String15       \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Vector{Int64\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     5.1      3.3      1.7      0.5  Iris-setosa         0  [1, 0, 0]    ⋯\n",
       "   2 │     4.7      3.2      1.6      0.2  Iris-setosa         0  [1, 0, 0]\n",
       "   3 │     6.9      3.1      5.4      2.1  Iris-virginica      2  [0, 0, 1]\n",
       "   4 │     6.3      3.4      5.6      2.4  Iris-virginica      2  [0, 0, 1]\n",
       "   5 │     7.7      3.0      6.1      2.3  Iris-virginica      2  [0, 0, 1]    ⋯\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e8a4bd-e14d-4b52-ae6a-8da65309378d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1b2553-997c-4518-b2fb-c4d7959f0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reduce(vcat,transpose.([df.f1, df.f2, df.f3, df.f4]))\n",
    "y = df.encoded_label\n",
    "\n",
    "split_fraction = 0.75 \n",
    "index = int(length(y)*split_fraction)\n",
    "\n",
    "X_train, X_test = X[:, 1:index], X[:, index + 1:size(df, 1)];\n",
    "y_train, y_test = y[1:index], y[index + 1:size(df, 1)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f2a51a-af23-47a2-8a71-1e4acd2f6b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: (4, 112)\n",
      "Size of train labels: (112,)\n",
      "Size of test set: (4, 38)\n",
      "Size of test labels: (38,)\n"
     ]
    }
   ],
   "source": [
    "println(\"Size of train set: \", size(X_train))\n",
    "println(\"Size of train labels: \", size(y_train))\n",
    "println(\"Size of test set: \", size(X_test))\n",
    "println(\"Size of test labels: \", size(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db03dd-7207-4e04-b786-1ae2693ec47e",
   "metadata": {},
   "source": [
    "### Define Network & Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b602f2b-b2f9-4b13-a8fb-4fba9fd2a74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(4 => 10, σ),                    \u001b[90m# 50 parameters\u001b[39m\n",
       "  Dense(10 => 3),                       \u001b[90m# 33 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m83 parameters, 588 bytes."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network = Chain(Dense(4,10,σ), \n",
    "                        #Dense(5,5,relu), \n",
    "                        Dense(10,3), \n",
    "                        softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69cc75c7-f719-4cb3-b370-59364849bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Likelihood\n",
    "    network\n",
    "end\n",
    "\n",
    "Flux.@functor Likelihood #tell Flux to look for trainable parameters in Likelihood\n",
    "(p::Likelihood)(x) = Multinomial.(1, [p.network(x)[:,i] for i in 1:size(x, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a053a129-c2bb-4170-9433-25209d1eaac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of weight parameters: 83\n"
     ]
    }
   ],
   "source": [
    "likelihood = Likelihood(neural_network)\n",
    "\n",
    "params, likelihood_reconstructor = Flux.destructure(likelihood)\n",
    "n_weights = length(params)\n",
    "println(\"No of weight parameters: \", n_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea34a8c1-d807-47f8-a709-056cc2d473d1",
   "metadata": {},
   "source": [
    "### Prior Distribution of Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff023f2-9087-4c13-8e32-3a7c542eb4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiagNormal(\n",
       "dim: 83\n",
       "μ: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "Σ: [1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0]\n",
       ")\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_prior = MvNormal(zeros(n_weights), ones(n_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de9fcd4-e035-4bfa-855a-d050396ab62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×150 Matrix{Float64}:\n",
       " 0.106954  0.104326  0.105824  0.0986519  …  0.0980669  0.10163   0.102563\n",
       " 0.375457  0.480985  0.373805  0.489617      0.526568   0.474298  0.472911\n",
       " 0.517589  0.414689  0.520371  0.411731      0.375365   0.424073  0.424526"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Verfiy the network output\n",
    "neural_network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1296c0c0-c758-4904-8d03-2f00e8534200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multinomial{Float64, Vector{Float64}}(n=1, p=[0.007249307221910489, 0.02229786632171394, 0.9704528264563755])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_reconstructor(rand(weight_prior))(X)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0575eef7-4fd3-44f0-8485-50ee8512747a",
   "metadata": {},
   "source": [
    "### Define the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913ab7df-f13d-4d43-a65d-fa0fdb347a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TuringModel (generic function with 2 methods)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function TuringModel(likelihood_conditional, weight_prior, X, y)\n",
    "    \n",
    "    weights ~ weight_prior\n",
    "\n",
    "    predictions = likelihood_reconstructor(weights)(X)\n",
    "    \n",
    "    for i in 1:length(y)\n",
    "        y[i] ~ predictions[i]\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a71bf7-33d6-49ba-bb72-8a9b460ea77d",
   "metadata": {},
   "source": [
    "### Posterior Samples using HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8a734f3-728b-4ecb-9c00-fd10c0664788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:31:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  Time taken: 1907.06 seconds\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(123)\n",
    "N = 500\n",
    "\n",
    "start_t = now()\n",
    "\n",
    "## We need to provide leapfrog step size, leapfrog step numbers \n",
    "ch = sample(TuringModel(likelihood_reconstructor, weight_prior, X_train , y_train), HMC(0.025, 10), N);\n",
    "weights = MCMCChains.group(ch, :weights).value #get posterior MCMC samples for network weights\n",
    "\n",
    "end_t = now()\n",
    "time_taken = (end_t - start_t) \n",
    "println(\"Total  Time taken: \", Dates.value(time_taken)/1000, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e989aca9-7f7c-4413-8381-a1ddaddda817",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weights = dropdims(mean(weights, dims = 1), dims=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d26016-3710-49f1-8dd8-40690699eea3",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "379f34e1-bdb9-4958-b2ba-ec410bdf9b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Function to compute accuracy and get the wrong predictions\n",
    "\n",
    "function accuracy(labels, predictions)\n",
    "    \n",
    "    acc = 0\n",
    "    wrong_predictions = []\n",
    "    for i in 1:length(labels)\n",
    "\n",
    "        if labels[i] == argmax(predictions[i].p) - 1\n",
    "            acc += 1\n",
    "        else\n",
    "            append!(wrong_predictions, [[int(labels[i]), argmax(predictions[i].p) - 1, predictions[i].p]])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    acc = acc / length(labels)\n",
    "    \n",
    "    return acc, wrong_predictions\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a151031-4762-4768-bc62-531ebabaf560",
   "metadata": {},
   "source": [
    "### Test Accuracy & Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22a1f3c1-5d97-4178-aec4-da33e62b5703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.9473684210526315\n",
      "\n",
      "Wrong Predictions :\n",
      "Actual : 1  Prediction : 2  Probability Scores :[0.0659060058795523, 0.3852927659165831, 0.5488012282038646]\n",
      "Actual : 1  Prediction : 2  Probability Scores :[0.0752304762891294, 0.35593520364135167, 0.5688343200695188]\n"
     ]
    }
   ],
   "source": [
    "test_labels = df.label[index + 1:size(df, 1)];\n",
    "test_preds = likelihood_reconstructor(vec(final_weights))(X_test)\n",
    "test_acc, wrong_preds = accuracy(test_labels, test_preds)\n",
    "println(\"Accuracy on Test Data: \", test_acc)\n",
    "\n",
    "println(\"\\nWrong Predictions :\")\n",
    "for i in 1:length(wrong_preds)\n",
    "    \n",
    "    println(\"Actual : \", wrong_preds[i][1], \"  Prediction : \", wrong_preds[i][2], \"  Probability Scores :\", wrong_preds[i][3])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabaacd7-e1ee-4fb6-8f45-b595485a6435",
   "metadata": {},
   "source": [
    "### Train Accuracy & Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73e44344-acae-41ec-8cd6-a34472d35635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train Data: 0.9553571428571429\n",
      "\n",
      "Wrong Predictions :\n",
      "Actual : 1  Prediction : 2  Probability Scores :[0.07714159801628445, 0.45340948997830377, 0.4694489120054119]\n",
      "Actual : 1  Prediction : 2  Probability Scores :[0.06994160482827576, 0.41298632346593583, 0.5170720717057884]\n",
      "Actual : 1  Prediction : 2  Probability Scores :[0.09609665769109921, 0.3854050138717216, 0.5184983284371791]\n",
      "Actual : 1  Prediction : 2  Probability Scores :[0.10127165739935705, 0.4213696189050848, 0.47735872369555826]\n",
      "Actual : 1  Prediction : 2  Probability Scores :[0.05374487672954314, 0.2870485390604867, 0.6592065842099702]\n"
     ]
    }
   ],
   "source": [
    "train_labels = df.label[1:index];\n",
    "train_preds = likelihood_reconstructor(vec(final_weights))(X_train)\n",
    "train_acc, wrong_preds = accuracy(train_labels, train_preds)\n",
    "println(\"Accuracy on Train Data: \", train_acc)\n",
    "\n",
    "println(\"\\nWrong Predictions :\")\n",
    "for i in 1:length(wrong_preds)\n",
    "    \n",
    "    println(\"Actual : \", wrong_preds[i][1], \"  Prediction : \", wrong_preds[i][2], \"  Probability Scores :\", wrong_preds[i][3])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd522f1-0b6f-4bf0-9889-19841fa747f4",
   "metadata": {},
   "source": [
    "### Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "230f1542-63d1-43e2-9937-278afd916c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: [ADVI] Should only be seen once: optimizer created for θ\n",
      "│   objectid(θ) = 13222727648826396137\n",
      "└ @ AdvancedVI C:\\Users\\khaitan\\.julia\\packages\\AdvancedVI\\W2zsz\\src\\AdvancedVI.jl:202\n",
      "\u001b[32m[ADVI] Optimizing... 100% Time: 0:16:09\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  Time taken: 984.582 seconds\n"
     ]
    }
   ],
   "source": [
    "start_t = now()\n",
    "\n",
    "advi = ADVI(20, 100)\n",
    "q = vi(TuringModel(likelihood_reconstructor, weight_prior, X_train , y_train), advi)\n",
    "\n",
    "end_t = now()\n",
    "time_taken = (end_t - start_t) \n",
    "println(\"Total  Time taken: \", Dates.value(time_taken)/1000, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf00e7-57b9-44c0-be78-08aaed7294ee",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3609c6ca-aa0d-4184-9a5a-488770a64cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction_vi (generic function with 2 methods)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Pick \"n\" samples od weights and get the predictions\n",
    "\n",
    "function prediction_vi(q, X, n_samples = 100)\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for i in 1:n_samples\n",
    "\n",
    "        sampled_weight = rand(q.dist)\n",
    "        test_preds = likelihood_reconstructor(vec(sampled_weight))(X)\n",
    "        append!(preds, [[argmax(test_preds[i].p) - 1 for i in 1:length(test_preds)]])\n",
    "    \n",
    "    end\n",
    "    \n",
    "    pred_matrix = reduce(vcat,transpose.(preds));\n",
    "    #println(\"Size of the prediction matrix:\", size(pred_matrix))\n",
    "    pred_out = [mode(pred_matrix[:, i]) for i in 1:size(pred_matrix, 2)];\n",
    "    \n",
    "    return pred_out\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d1c1a-c94b-4901-868a-d6a650487fea",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8d9262b-57fa-40a4-a9d6-fa4a7f4f5fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy_vi (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Function to compute accuracy and get the wrong predictions\n",
    "\n",
    "function accuracy_vi(labels, predictions)\n",
    "    \n",
    "    acc = 0\n",
    "    wrong_predictions = []\n",
    "\n",
    "    for i in 1:length(labels)\n",
    "\n",
    "        if labels[i] == predictions[i]\n",
    "            acc += 1\n",
    "        else\n",
    "            #println(\"Wong Prediction - Actual: \", int(labels[i]), \"  ---  \", \"Prediction: \", predictions[i])\n",
    "            append!(wrong_predictions, [[int(labels[i]), argmax(predictions[i]) - 1]])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    acc = acc / length(labels)\n",
    "    \n",
    "    return acc, wrong_predictions\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8138a5b-f8c6-47a1-b58b-a00fec01206f",
   "metadata": {},
   "source": [
    "### Test Accuracy & Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "554403f5-3cb4-430f-912c-91b583205ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.5\n",
      "\n",
      "Wrong Predictions :\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n"
     ]
    }
   ],
   "source": [
    "test_labels = df.label[index + 1:size(df, 1)];\n",
    "test_preds = prediction_vi(q, X_test)\n",
    "test_acc, wrong_preds = accuracy_vi(test_labels, test_preds)\n",
    "println(\"Accuracy on Test Data: \", test_acc)\n",
    "\n",
    "println(\"\\nWrong Predictions :\")\n",
    "for i in 1:length(wrong_preds)\n",
    "    \n",
    "    println(\"Actual : \", wrong_preds[i][1], \"  Prediction : \", wrong_preds[i][2])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d5405-d3b3-4af0-bb5e-99dee55f5df0",
   "metadata": {},
   "source": [
    "### Train Accuracy & Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0c4b77b-8697-44bd-aba6-8c1f1db67f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.7410714285714286\n",
      "\n",
      "Wrong Predictions :\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n",
      "Actual : 1  Prediction : 0\n"
     ]
    }
   ],
   "source": [
    "train_labels = df.label[1:index];\n",
    "train_preds = prediction_vi(q, X_train);\n",
    "train_acc, wrong_preds = accuracy_vi(train_labels, train_preds)\n",
    "println(\"Accuracy on Test Data: \", train_acc)\n",
    "\n",
    "println(\"\\nWrong Predictions :\")\n",
    "for i in 1:length(wrong_preds)\n",
    "    \n",
    "    println(\"Actual : \", wrong_preds[i][1], \"  Prediction : \", wrong_preds[i][2])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf3346-1b0e-4de6-84e6-7b501604b912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
